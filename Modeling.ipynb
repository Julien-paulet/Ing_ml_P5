{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sklearn\n",
    "import string\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from lxml import html\n",
    "import nltk\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,jaccard_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>desc</th>\n",
       "      <th>preprocessedTags</th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48320518</td>\n",
       "      <td>connect two differ databas one applic asp net ...</td>\n",
       "      <td>[mysql, .net, sql-server]</td>\n",
       "      <td>mysql</td>\n",
       "      <td>.net</td>\n",
       "      <td>sql-server</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48320543</td>\n",
       "      <td>bootstrap 4 navbar disappear resiz screen boot...</td>\n",
       "      <td>[html, angular, bootstrap-4]</td>\n",
       "      <td>html</td>\n",
       "      <td>angular</td>\n",
       "      <td>bootstrap-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48320558</td>\n",
       "      <td>xml transform xslt namespac xml transform xslt...</td>\n",
       "      <td>[xml]</td>\n",
       "      <td>xml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48320572</td>\n",
       "      <td>convert timestamp date various format swift co...</td>\n",
       "      <td>[ios, json, date, datetime]</td>\n",
       "      <td>ios</td>\n",
       "      <td>json</td>\n",
       "      <td>date</td>\n",
       "      <td>datetime</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44247</td>\n",
       "      <td>best practic requir time develop best practic ...</td>\n",
       "      <td>[project-management]</td>\n",
       "      <td>project-management</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                               desc  \\\n",
       "0  48320518  connect two differ databas one applic asp net ...   \n",
       "1  48320543  bootstrap 4 navbar disappear resiz screen boot...   \n",
       "2  48320558  xml transform xslt namespac xml transform xslt...   \n",
       "3  48320572  convert timestamp date various format swift co...   \n",
       "4     44247  best practic requir time develop best practic ...   \n",
       "\n",
       "               preprocessedTags                Tag1     Tag2         Tag3  \\\n",
       "0     [mysql, .net, sql-server]               mysql     .net   sql-server   \n",
       "1  [html, angular, bootstrap-4]                html  angular  bootstrap-4   \n",
       "2                         [xml]                 xml      NaN          NaN   \n",
       "3   [ios, json, date, datetime]                 ios     json         date   \n",
       "4          [project-management]  project-management      NaN          NaN   \n",
       "\n",
       "       Tag4 Tag5  \n",
       "0       NaN  NaN  \n",
       "1       NaN  NaN  \n",
       "2       NaN  NaN  \n",
       "3  datetime  NaN  \n",
       "4       NaN  NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned = pd.read_csv('data_cleaned.csv',\n",
    "                           converters={\"preprocessedTags\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "data_cleaned = data_cleaned.dropna(subset=['desc'])\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9852"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = data_cleaned.sample(frac =.30)\n",
    "sample.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample['desc']\n",
    "#Y = sample[['Tag1', 'Tag2', 'Tag3']].astype(str).values.tolist()\n",
    "Y = sample['preprocessedTags']\n",
    "mb = MultiLabelBinarizer()\n",
    "Y_encoded = mb.fit_transform(Y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in training data : 7881\n",
      "Number of data points in test data : 1971\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points in training data :\", X_train.shape[0])\n",
    "print(\"Number of data points in test data :\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.00009, max_features=5000)\n",
    "X_train_multilabel = vectorizer.fit_transform(X_train)\n",
    "X_test_multilabel = vectorizer.transform(X_test)\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=5000)\n",
    "tf = tf_vectorizer.fit_transform(X_train)\n",
    "tf_test = tf_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7881, 3968)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_multilabel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(list(X_train.str.split(' ')), size=250, window=5, min_count=20, workers=10, iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(doc):\n",
    "    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n",
    "    doc = [word for word in doc if word in w2v.wv.vocab]\n",
    "    return np.mean(w2v[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_train = pd.DataFrame(X_train)\n",
    "w2v_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-044bfc591122>:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  return np.mean(w2v[doc], axis=0)\n"
     ]
    }
   ],
   "source": [
    "w2v_train['doc_vector'] = X_train.apply(document_vector)\n",
    "w2v_test['doc_vector'] = X_test.apply(document_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_train = list(w2v_train['doc_vector'])\n",
    "w2v_test = list(w2v_test['doc_vector'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.quora.com/Whats-the-difference-between-gradient-descent-and-stochastic-gradient-descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.3405155535407983\n",
      "Param: {'estimator__alpha': 0.0001, 'estimator__loss': 'perceptron', 'estimator__penalty': 'elasticnet'}\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier())\n",
    "\n",
    "parameters = {\n",
    "    \"estimator__loss\": ['log','perceptron'],\n",
    "    \"estimator__alpha\": [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3],\n",
    "    \"estimator__penalty\":['l2', 'l1', 'elasticnet'],\n",
    "}\n",
    "\n",
    "model_tunning = GridSearchCV(clf, param_grid=parameters,\n",
    "                             scoring='jaccard_micro', n_jobs=-1)\n",
    "\n",
    "model_tunning.fit(X_train_multilabel, y_train)\n",
    "\n",
    "print(\"Best score:\", model_tunning.best_score_)\n",
    "print(\"Param:\", model_tunning.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='perceptron', alpha=0.0001, penalty='l1', n_jobs=11))\n",
    "clf.fit(X_train_multilabel,\n",
    "        y_train)\n",
    "y_pred = clf.predict(X_test_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.1476407914764079\n",
      "Weighted f1 score : 0.4530709141786762\n",
      "Micro f1 score : 0.49860491071428575\n",
      "Hamming loss : 0.005331695550392979\n",
      "Jaccard weighted score : 0.3364332524505588\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy :\",metrics.accuracy_score(y_test,y_pred))\n",
    "print(\"Weighted f1 score :\",metrics.f1_score(y_test, y_pred, average = 'weighted'))\n",
    "print(\"Micro f1 score :\",metrics.f1_score(y_test, y_pred, average = 'micro'))\n",
    "print(\"Hamming loss :\",metrics.hamming_loss(y_test,y_pred))\n",
    "print(\"Jaccard weighted score :\",metrics.jaccard_score(y_test,y_pred, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = OneVsRestClassifier(LogisticRegression(penalty='l2', n_jobs=-1))\n",
    "clf2.fit(X_train_multilabel, y_train)\n",
    "y_pred2 = clf2.predict(X_test_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.09944190766108574\n",
      "Weighted f1 score : 0.2903801207794255\n",
      "Micro f1 score : 0.34595456357114385\n",
      "Hamming loss : 0.004868843849858029\n",
      "Jaccard weighted score : 0.2052330834339875\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy :\",metrics.accuracy_score(y_test,y_pred2))\n",
    "print(\"Weighted f1 score :\",metrics.f1_score(y_test, y_pred2, average = 'weighted'))\n",
    "print(\"Micro f1 score :\",metrics.f1_score(y_test, y_pred2, average = 'micro'))\n",
    "print(\"Hamming loss :\",metrics.hamming_loss(y_test,y_pred2))\n",
    "print(\"Jaccard weighted score :\",metrics.jaccard_score(y_test,y_pred2, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = OneVsRestClassifier(SVC(C=2,\n",
    "                              kernel='rbf',\n",
    "                              degree=1))\n",
    "svc.fit(X_train_multilabel, y_train)\n",
    "y_pred_svc = svc.predict(X_test_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.17097919837645864\n",
      "Weighted f1 score : 0.43476645096646427\n",
      "Micro f1 score : 0.49585025604803107\n",
      "Hamming loss : 0.004235389759702826\n",
      "Jaccard weighted score : 0.32641824844154615\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy :\",metrics.accuracy_score(y_test,y_pred_svc))\n",
    "print(\"Weighted f1 score :\",metrics.f1_score(y_test, y_pred_svc, average = 'weighted'))\n",
    "print(\"Micro f1 score :\",metrics.f1_score(y_test, y_pred_svc, average = 'micro'))\n",
    "print(\"Hamming loss :\",metrics.hamming_loss(y_test,y_pred_svc))\n",
    "print(\"Jaccard weighted score :\",metrics.jaccard_score(y_test,y_pred_svc, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.057735097744180355\n",
      "Param: {'estimator__alpha': 0.0001, 'estimator__loss': 'perceptron', 'estimator__penalty': 'elasticnet'}\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier())\n",
    "\n",
    "parameters = {\n",
    "    \"estimator__loss\": ['log','perceptron'],\n",
    "    \"estimator__alpha\": [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3],\n",
    "    \"estimator__penalty\":['l2', 'l1', 'elasticnet'],\n",
    "}\n",
    "\n",
    "model_tunning = GridSearchCV(clf, param_grid=parameters,\n",
    "                             scoring='jaccard_micro', n_jobs=11)\n",
    "\n",
    "model_tunning.fit(np.array(w2v_train), y_train)\n",
    "\n",
    "print(\"Best score:\", model_tunning.best_score_)\n",
    "print(\"Param:\", model_tunning.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='perceptron', alpha=0.0001, penalty='l1', n_jobs=11))\n",
    "clf.fit(w2v_train,\n",
    "        y_train)\n",
    "y_pred = clf.predict(np.array(w2v_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.015728056823947234\n",
      "Weighted f1 score : 0.04785225199096601\n",
      "Micro f1 score : 0.08958837772397095\n",
      "Hamming loss : 0.007809138947487101\n",
      "Jaccard weighted score : 0.02749999585953673\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy :\",metrics.accuracy_score(y_test,y_pred))\n",
    "print(\"Weighted f1 score :\",metrics.f1_score(y_test, y_pred, average = 'weighted'))\n",
    "print(\"Micro f1 score :\",metrics.f1_score(y_test, y_pred, average = 'micro'))\n",
    "print(\"Hamming loss :\",metrics.hamming_loss(y_test,y_pred))\n",
    "print(\"Jaccard weighted score :\",metrics.jaccard_score(y_test,y_pred, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3a710d2a84f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open('Flask/tfidf', 'wb'))\n",
    "pickle.dump(clf, open('Flask/model', 'wb'))\n",
    "pickle.dump(mb, open('Flask/mb', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_convertor = mb.classes_\n",
    "classes_convertor = pd.DataFrame(classes_convertor)\n",
    "classes_convertor.to_csv('Flask/classes_convertor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.00001, penalty='l2', n_jobs=11))\n",
    "clf.fit(X_train_multilabel, \n",
    "        y_train)\n",
    "y_pred = clf.predict(X_test_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervized approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 50\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.1, l1_ratio=0.5, n_components=50, random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf = NMF(n_components=n_components, random_state=42,\n",
    "          alpha=.1, l1_ratio=.5)\n",
    "\n",
    "nmf.fit(X_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', learning_offset=50.0,\n",
       "                          max_iter=5, n_components=50, random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=42)\n",
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we actually have the different tags of each post, we'll try to analyze which topic goes with which tag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
